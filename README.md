# AICode-compass

---

## All people read this article :   )

        我相信您一定感受到我们与计算机交互以及编代码的方式正在发生巨大的变化。这场深刻的变革涉及我们使用的工具、编程的方式，甚至延伸到我们对软件产品和软件系统的思考方式。
    
        而且这种变化速度非常快！
    
        新的大语言模型（LLM）每周都在发布，如GPT-5、Claude4、Gemini-2.5 Pro、Grok-4….。新的工具、新的编辑器（IDE）、新的 vibe coding 实践、新的协议（Protocol），如 MCP、A2A、SLOP 等等……要跟上所有这些实在太难了。一切都散落在不同的地方，如网站、个人博客、代码库、YouTube 视频等。

这就是我们决定编写本指南的原因。我们尝试将所有内容整合在一起，以易于理解、简洁明了的形式，在同一个地方向您介绍围绕 AI 编程或 AI 辅助代码生成的实践和工具。

> AICode的方式和最佳实践在随时发生骤变，聚合并探索这些信息是我们唯一的目的！

## Who It’s For?

- **如果您从未编过代码（例如产品经理、设计师、个人创业者），但对这种新的vibe coding方式感兴趣，那么本指南绝对适合您。**

  ——*我们将尽力消除晦涩难懂的部分，只留下必须所需的知识，对什么是真正重要的进行说明以及对“只是炒作”的内容进行批判（例如隔天就出现在新闻文章标题里的“震惊！颠覆！王炸！…”*🫠*）。这样，您可以不被外行或者新闻扰乱视听，直接使用vibe coding的方式构建你的软件产品或者UI界面，尽管您未曾系统学过编程。*

- **如果您是一名程序员，但尚未开始使用 AI 代码助手，本指南就是为您准备的。**

  ——*它介绍了最新的工具和良好实践，帮助您逐步把 AI 融入日常工作，让它成为提升效率和创造力的得力助手。*

- **如果您是一名程序员，并有过AI辅助编程的经验，本指南也同样适合你。**

  ——*我们将汇总前沿的趋势、协议与实践方式，帮助您更系统地理解 AI 编程生态，避免在信息碎片中迷失。无论您是想进一步提高生产力、探索代理模式下的自动化，还是思考如何在团队或项目中合理使用 AI，本指南都能为您提供参考与启发。*

🙂 让我们开始吧！

## 从 AI coding 到 vibe coding

这些术语非常相似，本质上也并没有太大区别。

        AI 编程是指使用 AI 模型及其所有相关工具来帮助您编写软件。在学术界，他们通常被划分为不同的子任务，例如 AI 代码生成（或简称为代码生成，以下同样省略 AI），代码摘要，自动修复，自动测试。
    
        这是一个迷人的研究领域，它在学术界正在被如火如荼地研究。

---

📚 Resources —— 学术界的热点关注

- https://www.swebench.com/ —— SWE-bench Team (Princeton University, University of Chicago, Stanford University)
- https://www.tbench.ai/ —— Terminal-Bench Team (Laude, Microsoft, Anthropic)
- ……

---

但是，本文章主要关注实践中的 AI 编程：如果您正在使用 Cursor 并通过不断地“tab-tab-tab”来获取补全，您就是在AI 编程；如果您完全使用 Cursor 的代理模式，您也是在AI 编程。总而言之：它是任何利用 AI 模型帮助您生成代码的方式。

Vibe coding是 AI 编程的升级版 → 在这里，您不太关心生成的代码，您只需提供一个提示，并期望 AI 为您编写所有代码。这个术语由卡帕西 (Karpathy) 在 2025 年创造，并且越来越受欢迎。

恕我直言，vibe coding正在帮助那些从未考虑过编程的人普及编程！总而言之，无论您是使用 AI 来讨论您的软件想法，还是仅仅帮助修改您现有代码库的一部分，或者您是完全采用vibe coding，您都在使用 AI 来帮助您生成代码。我们称之为 AI coding。

相信您在各个网站或论坛（例如Github、小红书、X等）都或多或少看到过介绍 AI 编程使用的建议，但总而言之，它们都可以被归结为两个high-level的方式：

- **AI 是您的驾驶员：**顾名思义，在这种情况下由AI主导你的开发。这里是vide coding发生的地方。您打开 Cursor Agent 的 YOLO 模式，并相信代理所做的一切来生成您的代码。这是一种非常强大的自我自动化方式，但它要求在如何设计系统、驯服代理以及跳入您实际上不了解的意大利面条式代码（特别是为了解决错误）方面，需要一些良好的实践。
- **AI 是副驾驶：** 您使用 AI 模型来增强自己，提高您的生产力。无论是启动 ChatGPT 来帮助您为您的 SaaS 进行头脑风暴，还是使用 Cursor 自动完成您的文档字符串。这有很多好处，特别是对于创意探索和自动化您工作中无聊的部分。

值得注意的是，随着项目复杂性的增加，我们大多都会回归副驾驶模式，并远离纯粹的 YOLO vibe coding。如果未来有另一个人（或者三个月后的你自己）需要维护代码的可能性越大，这一点就越重要。

## 🕹️Vibe Coding - AI 作为驾驶员

### **开始**

如果您不会编程，但想尝试一下，我们建议从一些Web工具开始，如 Bolt、Replit、v0 或 Lovable。

如果您已经会编程，最推荐的是 Cursor 或 Windsurf。您可以从免费计划开始，然后升级到每月 20 美元的计划。如果您将使用大量的token用于最新的LLM，那么 Cursor 相当不错且便宜。VSCode 最近也推出了自己的代理模式。它与 Github Copilot 配合使用，重点是学生有教育免费。其他编辑器也在迅速添加代理功能，我们将在最后总结它们。[All tools](https://www.notion.so/All-tools-26594337c93f80e2bc3aca886b855481?pvs=21) 

如果您想要一个更开源的替代方案，请尝试 OpenHands。

如果您已经会编程并且是一个终端狂人，请尝试CLI工具，例如aider、Claude Code 、 OpenAI Codex 或 Gemini CLI。对于这些工具，您需要为 Anthropic Claude、OpenAI GPT 或 OpenRouter 设置 API 密钥。

如果您已经会编程，喜欢终端和 VSCode 的风格，并且真的想体验让子代理并行运行的强大功能，并且不关心成本，只关心完成任务，请尝试 Amp。

<aside>
💡


**建议-1**

我们强烈建议您在类似 OpenRouter、硅基流动、ChatAnyWhere 等LLM集成调用网站中创建一个账户。这非常简单，您将获得最新 LLM 模型的访问权限，甚至是它们的免费版本。例如，如果你使用CLI那么建议首选Gemini 2.5 Pro，它不仅强大而且可以通过 OpenRouter 免费使用（有每日免费额度）。

注：硅基流动和ChatAnyWhere对国内友好，但是前者只能访问国内LLM。

</aside>

<aside>
💡


**建议-2**

我们建议你先从Cursor开始，因为它不仅强大、操作友好，更重要的是，提供了便宜的套餐来使用类似Claude-4、GPT-o系列等昂贵的模型

</aside>

---

📚 Resources —— 推荐的 AI Code 工具

- https://bolt.new/
- https://replit.com/
- https://v0.app/
- https://cursor.com/cn
- https://windsurf.com/
- https://docs.all-hands.dev/
- https://arxiv.org/pdf/2407.16741? - Openhands论文链接
- https://aider.chat/
- Claude code封锁国内ip，不推荐使用
- https://openai.com/index/openai-codex/
- https://github.com/google-gemini/gemini-cli

---

### 如何为Vibe Coding提供提示(prompt)？

在您安装并使用这些工具一段时间后，您会注意到它们会出现幻觉、陷入无限循环尝试修复可能存在的错误等。重要的是要知道如何写好提示。以下是一些提示：

- **不要在一个提示中问所有问题。** 仅仅提示“嘿，给我为我的宠物店建一个应用程序”对软件工程师和 AI 都没有多大帮助 →了解您的项目，先与 LLM 进行头脑风暴，创建一个 PRD（Production Requirement Document, 产品需求文档），制定计划并将其分解为任务。

  事实证明，如果您让您心爱的 LLM 自由发挥，没有太多上下文，它会很快产生相当狂野的幻觉。您需要驯服这头野兽，而 PRD 是一个很好的方法。

  下面将提供一个如何使用 ChatGPT 为您创建一个 PRD 的方法。

- **提供详细信息。** 如果您知道自己想要什么，就说出来。如果您知道自己想要哪种编程语言、哪种技术栈、哪种受众类型，请将其添加到您的提示中。正如这篇长达60页的关于程序修复的综述论文(https://dl.acm.org/doi/pdf/10.1145/3764584)里提到的，你提供什么样的信息将直接决定着你获得的效果以及成本。

  <aside>
  💡


  ![img/image.png](https://raw.githubusercontent.com/yepYoung/aicode-compass/main/img/image.png)

  ![img/image.png](https://raw.githubusercontent.com/yepYoung/aicode-compass/main/img/image1.png)

  </aside>

- **Markdown 对于 LLM 来说很友好。**为了强调提示的特定部分，建议使用一些符号，如 ##，**。

- **将您的项目分解为任务和子任务。**

- **针对不同的目标尝试不同的模型。**

- **尝试不同的模型来确认和验证其他模型的输出。**

👉**[示例]**  一种通常效果良好的方法/程序/策略/工作流程

使用 ChatGPT 4.5、4o 或 o3 并使用以下提示：

```
你是一位资深软件工程师。我们将一起构建一个项目的 PRD。

重要：
- 一次只提一个问题
- 每个问题都应基于之前的答案
- 深入探讨每个重要的所需细节

想法：
<在这里输出你的想法>
```

您将进入一个问答循环几分钟。尽量详细地回答您能回答的所有问题。完成后（或当您觉得足够时），发送此提示以引导模型将其编辑为 PRD：

```
将这些发现编辑成一个 PRD。使用 Markdown 格式。它应该包含以下部分：

- 项目概述
- 核心需求
- 核心功能
- 核心组件
- 应用程序/用户流程
- 技术栈
- 实施计划
```

将此文件复制并保存到您的项目文件夹中的 `docs/specs.md`。

现在让我们为您的项目创建任务列表。询问以下问题：

```
根据生成的 PRD，创建一个详细的分步计划来构建此项目。
然后将其分解为相互依赖的小任务。
根据这些任务，将其分解为更小的子任务。
确保步骤足够小，以便一步实现，但又足够大，以便成功完成项目。
使用软件开发和项目管理的最佳实践，避免大的复杂性跳跃。
将任务相互关联，创建依赖列表。不应有孤立任务。

重要：
- 使用 markdown
- 每个任务和子任务都应该是一个清单项
- 为每个任务提供足够的上下文，以便开发人员能够实现它
- 每个任务都应有一个数字 ID
- 每个任务应列出依赖任务 ID
```

将其保存为您的项目文件夹中的 `docs/todo.md`。

这是一个使用 ChatGPT 4o 为一个简单的 CLI/IDE 工具进行的头脑风暴/规划会话的示例，可以作为您的灵感。

有了以上这些，您就可以打开 Cursor（或其他 AI 代码编辑器），将其指向这些文件并询问：

```
你是一位资深软件工程师。研究 @docs/specs.md 并实现 @docs/todo.md 中
仍缺少的部分。每次实现一个任务，并尊重任务和子任务的依赖关系。
完成一个任务后，在列表中勾选它，然后进行下一个。
```

当 Cursor Agent 第一次执行命令时启用 YOLO 模式，然后继续在提示中接受或请求继续。

在使用 Cursor 的情况下，有时 LLM 会达到某些限制并要求重试。只需重试并继续即可。是的，您正在vibe coding！

<aside>
💡


**建议-3**

尽管vibe coding非常酷，但了解您在做什么也同样有趣 → 审查代理生成的代码会在出现错误时（它们一定会发生！）对您有很大帮助，并提高您代码审查的技能。

Note：*如果您关心AICoding，相信您一定看过类似的话：未来的程序员将更少关心编程实现，取而代之的，他们将成为一个设计师（关心软件架构和顶层设计）和代码审查员（审查代码以解决AI出现的错误）。这非常正确！*

</aside>

### **我应该使用哪种模型？**

LLM 经过不同的目标训练和微调将适应不同的任务，这里列出了您可能拥有的目标/用途以及应该使用哪种模型：

| **目标** | **模型（国外）**                                          | 模型（国内）                                 |
| -------- | --------------------------------------------------------- | -------------------------------------------- |
| 头脑风暴 | GPT 5, 4o, o3, Grok                                       | GLM-4.5, DeepSeek-R1, KiMi-K2                |
| 编程     | Claude Sonnet 4, Gemini 2.5 Pro, Grok, GPT 5, o3, o4-mini | Qwen3-Coder, Qwen 系列, DeepSeek-V3, KiMi-K2 |

鉴于 LLM 每天都在变化，此表格很快就会过时。请查看以下排行榜以获得更准确的比较：

---

📚 Resources —— LLM可信排行榜

- 通用排行榜
  - https://lmarena.ai/leaderboard
  - https://models.dev/
  - https://openrouter.ai/models?categories=programming&fmt=table
  - [Agent Leaderboard - a Hugging Face Space by galileo-ai](https://huggingface.co/spaces/galileo-ai/agent-leaderboard)
- 代码任务排行榜
- https://www.swebench.com/
- https://swe-bench-live.github.io/
- https://aider.chat/docs/leaderboards/

---

### **为你的项目设置规则**

您可以通过将规则或约定“注入”LLM 的上下文来定义将应用于您项目的规则或约定。每个编辑器都有一些方法可以做到这一点：

- 在 Cursor 中，只需在 `.cursor/rules/` 文件夹中创建 Markdown 文件 或者 在Cursor Setting 的 Rules中编辑即可。Cursor 将确保将这些规则应用于与 LLM 的所有通信。
- 在 Aider 中，创建包含您要使用的规则/约定（如 `rules.md`）的 Markdown 文件，然后将以下内容添加到您的 `.aider.conf.yml` 文件中：`read: rules.md`。

此外，许多工具支持在您的主目录中配置一个规则/约定文件，以应用于您的所有项目。例如，在 Aider 中，您可以在名为 `~/.global_conventions.md` 的文件中添加全局约定，然后将其添加到 `.aider.conf.yml` 中，使用 `read: [~/.global_conventions.md, rules.md]`。

您可以将 PRD 的一部分作为规则添加，例如技术栈或一些代码格式和样式指南。

以下是一些规则指南，希望能给您带来启发：

👉**[示例]**  规则分类

1. 代码风格
   - 缩进方式（如 2 空格 / 4 空格 / Tab）
   - 命名约定（变量、函数、类、文件名）
   - 注释风格（是否要求 Javadoc / docstring / 注释语言统一为英文）
   - 空行与空格使用规则（操作符两侧是否空格、函数之间空行数）
2. 架构与技术栈约定
   - 指定技术框架（如 Spring Boot、React、Next.js）
   - 数据库与 ORM（MySQL + JPA / PostgreSQL + Prisma）
   - API 风格（REST / GraphQL / gRPC）
   - 日志规范（统一使用 slf4j / logback，日志分级策略）
   - 错误处理（统一异常封装类、返回码规范）
3. 代码安全与质量要求
   - 禁止硬编码（如 API key、密码）
   - 输入校验必须存在
   - 异常必须捕获或显式抛出，不允许吞异常
   - 必须添加单元测试 / 覆盖率要求（如 ≥ 80%）
   - 依赖安全检查（不使用过时库 / 存在 CVE 的库）
4. 文档与注释
   - 必须为公共 API、类、模块写文档注释
   - README 格式（项目介绍、安装步骤、运行方法、示例）
   - 代码中复杂逻辑必须有解释注释
   - 提交时要求附带变更说明
5. Git 工作流与提交规范
   - Git 分支策略（main/dev/feature/bugfix 命名规范）
   - Commit message 规范（如 Conventional Commits：`feat: xxx`, `fix: yyy`）
   - PR / MR 模板（必须写清楚修改内容、影响范围、测试方法）
6. 测试与 CI/CD 约定
   - 单元测试框架（JUnit、pytest、Jest）
   - Mock 策略（如统一用 Mockito）
   - 覆盖率检查规则
   - CI 工具（GitHub Actions / GitLab CI / Jenkins）
   - 自动化 lint & format 检查
7. 项目专属规则
   - 与 PRD 相关的专属约定（如“前端必须用 Tailwind CSS”，“接口响应时间需 <200ms”）
   - 特殊的业务逻辑约束（如“所有金额字段必须用 BigDecimal，而非 float/double”）
   - 团队内部习惯（如“类名前缀必须加 `App`”，“所有 API 接口返回统一的 JSON 包装格式”）

### **保留提示日志**

记录您发送的每个提示，并（这一点很重要）附上您对思考过程的评论以及您遇到的任何意外情况。这个提示日志是您的设计意图记录；对于任何没有参与项目的人，包括您在六个月后忘记了自己当时在想什么，都将非常宝贵。

目前还没有关于此文件名称的约定，您可以使用 `history.md` 等名称，并在交互中及时更新这个文档。有了这个文件，您就可以在其中添加自己的想法。当您将来回顾项目时，您（和他人）可以学到很多东西，而且您可能会开始注意到一些模式和技巧，可以在下次会话中使用。

### 开发实践 - 结构化设计与提示

LLM 在生成可用代码方面已经相当成熟，但在结构良好——即具有适当分层、关注点和职责分离的代码方面仍然不足。良好的结构直接关系到 **可读性、可维护性和缺陷率。**

<aside>
💡


**建议-4**

- 按层次逐步提示：在数据库驱动应用中，先定义数据模型 → 再构建数据访问层 → 最后编写业务逻辑。
- 保持分层清晰：在项目规则中明确要求 LLM 不要打破分层。如果需要新方法，必须放入对应封装层，而不是直接侵入业务逻辑。
- 核心优先：花时间确保主要功能得到实现并按照您想要的方式组织。您甚至可以编写类和函数骨架，然后让 LLM 填补空白。只有在您拥有良好的基础和良好的测试之后，您才能转向此核心库的消费者，例如将其作为 CLI 或 REST API 公开给未来的 Web 应用程序。
  </aside>

### 开发实践 - **前端/Web应用开发**

现代 Web 开发的生态系统庞杂且快速演化，往往令人望而生畏。无论是 JavaScript/TypeScript 框架，还是 CSS/UI 框架，都让人很难决定从哪里开始、又该选择哪一个。经过几周的前端开发实践，我最终总结出以下几种值得尝试的方案：

- **Next.js**：如果你希望与 **Vercel** 的生态系统紧密结合，Next.js 是一个极佳的选择。它提供了良好的开发体验和丰富的功能集。但要注意，随着项目规模增长，Vercel 的费用可能会很快变得昂贵。
- **Vanilla React + React Router**：如果你希望拥有更强的部署灵活性，可以选择最基础的 React，并结合 React Router 实现路由功能。这样你几乎可以将应用部署到任意平台，而不依赖特定的生态系统。
- **Remix**：Remix 在路由处理方面具有出色的特性，同时也能像 React Router 一样自由部署。它非常适合需要良好 SEO、服务端渲染和渐进增强的项目。
- **FastHTML**：如果你更倾向于 Python 生态，并且关注的是暴露后端核心功能（如数据分析或 AI/ML 管道），而非复杂的 UI，那么 FastHTML 是一个轻量化但实用的选择。

在实际案例中，像 **Lovable** 这样的基于 Web 的 AI 编程平台选择了 React，而 **v0** 则构建在 Next.js 之上。
一个实用的小技巧是：你可以先在 Lovable 上启动项目（它的免费计划每天提供最多 5 条消息），并将输出直接同步到 GitHub 仓库。随后，你只需在本地机器上克隆该仓库，就能切换到 **Cursor** 等编辑器继续 AI 编程，然后再将成品部署到 **Render**、**Fly.io**、**Cloudflare** 等任意平台。这种工作流没有任何绑定或限制，尤其适合在后端包含复杂逻辑时使用。

如果你同时在开发前端和后端，建议：

- 将后端和前端分别放置在 Git 仓库的独立子目录；

- 或者为后端和前端建立单独的仓库，然后将它们一起导入到 Cursor 的同一工作区。

  这样，你在前端代理中就能轻松引用后端代码，反之亦然，避免了跨目录引用的麻烦。

另外，前期不要过早集成前端和后端。更好的做法是指示 AI 代理在开发前端时使用 **模拟数据（mock data）** 或 **虚拟 API**，等后端功能完善后再替换为真实数据源。

一个进阶的技巧是：借助优秀的 **MCP 工具**，将编程代理集成到 **Playwright** 或 **browser-use** 中。这样，AI 代理可以自动控制浏览器、捕捉错误和截图，而无需你手动复制粘贴浏览器报错信息回到 AI 循环中，极大地减少调试的摩擦。

如果你希望在 Web 应用中加入 **3D 内容**，且使用的是 React，那么建议使用 **React Three Fiber (R3F)**，而不是直接使用 three.js。R3F 将 three.js 对象封装为 React 组件，使得状态管理与 React 的数据流保持一致，更容易构建复杂的 3D 交互。

### **开发实践 - 后端开发**

与前端不同，后端开发在 Lovable 等基于 Web 的工具中并不理想。因此你可能需要转向更专业的工具，比如 **Cursor**、**Windsurf**、**aider** 等本地开发环境。

推荐的后端技术栈：

- **Python + FastAPI**：轻量化、文档生成优雅、性能良好，非常适合快速构建 RESTful API 或 AI 服务接口。
- **Node.js + Express / NestJS**：如果你更希望与前端保持统一语言（JavaScript/TypeScript），那么 Express 或更结构化的 NestJS 是不错的选择。

后端开发的一个关键是 **端到端测试（E2E）**。你可以引导 AI 在为每个新功能或子任务编写实现的同时，自动生成对应的测试并运行它们，从而保证稳定性。

在完成后端开发后，可以将后端的 **API 文档（特别是 HTTP 端点说明）** 提供给前端代理。这样，前端就可以从使用虚拟数据逐渐切换到真实的后端接口，保证迭代的平滑过渡。

### **开发实践 - 游戏**

对于小型游戏项目，可以采取极简主义的方式：

- 使用一个独立的 `.js` 文件完成全部逻辑。
- 如果是 3D 游戏，选用 **three.js**；如果是 2D 游戏，则推荐 **pixi.js**。

在游戏开发中，**优质的素材（assets）** 往往比引擎本身更重要。因此你可以使用 **Tripo AI**、**Anything World** 等服务生成 3D 资产，并自动完成绑定与动画，大幅提升开发效率。

### **如何创建我自己的 AI Code代理？**

我们正在制作一些关于如何通过构建我们自己的工具来创建 AI 编程代理的教程，所以请持续关注。从一些既有的开源Agent及其论文里面学习是最好的方式，例如OpenHands、SWE-Agent…

[如果您有相关的启发或者讨论，可以随时联系我们：522023320186@smail.nju.edu.cn](mailto:如果您有相关的启发或者讨论，可以随时联系我们：522023320186@smail.nju.edu.cn)

## 🗺️远离纯粹的vibe coding - AI作为副驾驶

假设现在你已经使用AI成功构建好了你软件项目的第一个版本，你使用PRD、子任务文档和预设的规则幸运地在几次或一次交互中生成代码、解决bug/issue、启动服务。

但是不幸的是，至此，您纯粹的vibe coding之旅就要结束了。之后，你必须逐渐花费更多的脑力从AI手里夺过方向盘，坐到主驾驶的位置。

我们希望通过分享下面的几点或深层或显而易见的思考，来说明你必须让AI回到副驾驶位置的原因：

<aside>
💡


**思考**

1. **上下文窗口永远显得不足**

   无论是 32k、64k、256k、100 万 tokens，还是更大，提示工程师们总会希望塞入更多代码与上下文。过去我们只能放两三个文件，将来可能会希望一次性放入几十甚至上百个文件。
   你不可能把整个代码库的代码全部给LLM，而LLM也很难准确地检索到你想要修改或者审查的代码位置。

2. **LLM在软件设计上远达不到人类专家水平**

   这一方面来自于LLM上下文窗口不足（无法看到并分析代码库的全貌），另一方面源于其缺乏真正的架构性思维与抽象能力。

   人类专家在软件设计时会考虑长期演进、团队协作、可维护性、性能权衡、安全性与合规性等多重因素，而 LLM 更像是基于已有数据和模式的“局部补全器”。这意味着 LLM 擅长的是战术层面的代码生成与修改，而在战略层面的架构设计、模式选型、需求折中、权衡取舍方面，它仍然无法达到人类的深度与远见，结果是：LLM 生成的代码往往可用，但可能导致架构上的碎片化、重复造轮子、缺乏一致性和统一标准。

3. **维持项目稳定并持续测试和演进需要人来主导**

   一方面，AI 的幻觉和输出的不确定性，将轻易地破坏项目的稳定性，例如已经实现的功能。尤其是当我们把修改、测试、执行的权限AI全部交给AI时，这种担忧更为突出。（例如，为了测试通过，（绝大部分）LLM都倾向于给很简单的测试用例或者直接修改被测试代码来适配测试用例🫠）

   另一方面，项目后期面临的不再是“能不能跑起来”的问题，而是**该往哪里发展**。是优化性能还是优先扩展功能？是提高用户体验还是保证合规与安全？这些权衡涉及商业逻辑、团队目标与用户价值判断，而这正是人类专家的独特优势。

</aside>

因此，在接下来的内容里，我们将提供一些更细致的指南以提升LLM表现的上限。
🙂 让我们开始吧！

### 关联准确的/更多的上下文

您可以把和AI辅助的过程理解为一起打扫房间，你花更多的时间“视察”并给出要打扫的地方，LLM就能把房间的角落清扫地更准确、更彻底。

因此，给LLM准确和更多的上下文是非常有必要的。例如，使用@符号给Cursor的Chat模块更多的代码信息。

此外，你也可以使用 **repomix** 或 **files-to-prompt** 将代码打包注入到 LLM 的上下文窗口，提升代码理解能力。

一个high-level的原则是：**聚焦任务级别，而非整个项目。**因此，你应该分层次提供上下文。以下的分层将项目分为三个层次：

- 顶层：项目目标、核心架构原则
- 中层：相关模块接口、设计模式说明
- 底层：具体函数或测试文件

例如，您可以针对单一功能点编写一个迷你 PRD，然后引导 Cursor Agent 实现它。这种方式就像指导一名初级开发者处理一个 GitHub issue，效果更佳。

### **我如何处理错误和 Bug？**

关于编程和软件，您必须知道一件事：它们会失败。无论您尝试如何防止，都会发生。所以，我们首先接受它并与错误和 Bug 成为朋友。

这里的第一个策略是模仿软件工程师的做法：查看解释器/编译器给您的错误消息，并尝试理解它。复制并粘贴错误回到 LLM，并要求它给出错误原因并且修复它。另一个好主意是添加像 BrowserTools 这样非常适合调试的 MCP 工具，它们能够自动捕捉、分析并反馈浏览器端的错误，减少人工干预。

### 关注代码风格

以下是我们整理的代码风格建议，这些建议在保持代码可读性的同时最大化帮助 AI 理解并完成代码任务（尤其是在解决上下文爆炸问题上）：

- **最小化不必要的缩进、空格与换行**，保持代码紧凑。
- **顶层函数、类和模块名称**尽量使用完整的命名规范。函数/类/模块内部的代码（尤其是临时变量）应缩短变量名，以减少代码体积。
- **为顶层函数、类和模块提供简要但必要的注释**，说明其目的、输入与输出。函数内部除非必要，不添加注释。
- **尽量在单个文件中实现更多相关的函数、类或模块**。仅在功能模块确实独立时才拆分到不同文件。
- **使用高级语言特性来缩减代码量**，例如在合适场景下优先使用 Lambda 函数代替完整函数定义；利用语法糖；在 C++、TypeScript 等静态类型语言中使用类型推断减少冗长声明。
- **可复用的模块、函数或类应抽象为独立单元**，以便重用并减少整体代码体积。
- **避免重复代码**（如相似逻辑或函数），优先使用高阶函数、装饰器或 mixins 封装通用逻辑。
- **使用第三方库时，优先选择简洁高效的库**，满足功能需求的同时避免过多开销。

### **MCP、SLOP 和 A2A 是什么，我如何从中受益？**

MCP 是模型上下文协议（Model Context Protocol）的缩写。它由 Anthropic 开发，但现在 OpenAI 的 GPT 和 Google 的 Gemini 等其他 LLM 也开始考虑使用它。这是一个强大的概念，并且与另一个概念紧密相连：函数/工具调用。

工具调用是 LLM 调用工具或函数来执行某些操作的一种方式。它是一种更新 LLM 知识窗口（基于过去数据训练）以获取新信息，同时将其与外部工具和端点集成的方式。例如，如果您想在网上搜索某些信息，您可以指示 LLM 使用执行此操作的工具（例如：“嘿，如果您需要在网上搜索，请使用此工具：search(term)”）。然后，LLM 将调用该工具，获取输出，并在为您生成新预测时使用它，而不是花费大量的令牌、迭代步骤和解析工作负载。

MCP 通过为此创建标准来扩展这个想法。这样我们就可以创建一个 MCP 服务器，该服务器将向 LLM 公开某些资源（例如数据库）或工具（例如将计算某些内容并返回结果的特定软件）。

等等，但这不只是一个 API 吗？我不能用 REST API 服务器/客户端和 LLM 提示中的一些解析来模拟同样的事情吗？有点像，这也是 SLOP（Simple Language Open Protocol）所提出的。然而，拥有像 MCP 这样的标准使得确保 LLM 原生支持它而无需客户端进行额外的解析和技巧变得更容易。

A2A（Agent to Agent Protocol）在游戏中非常新。它由 Google 创建，旨在“补充”MCP，专注于多代理通信，而 MCP 则专注于 LLM-工具通信。

**重要提示：** 有很多优秀的 MCP 服务器，Cursor 等编辑器也支持它们。目前，只有 Anthropic Claude LLM 支持它们，因此当您想使用 MCP 工具时，请确保使用 Claude。

Anthropic 在此维护了一个更新的 MCP 服务器列表：[https://github.com/modelcontextprotocol/servers](https://github.com/modelcontextprotocol/servers)

### 我该如何让AI辅助测试？

是的，测试比以往任何时候都更加重要。在 2025 年的最新技术水平下，LLM 善于生成清晰正确的代码，但它们有时会产生幻觉——更重要的是，它们可能会无法理解规范并生成正确的代码来做错误的事情。

即使我们获得了完全人类水平的通用人工智能，这种情况也不太可能改变——毕竟，人类也会误解规范！语言的模糊性是测试在未来仍然重要的原因。

使用 TDD 来创建您想要的结果骨架可以真正帮助引导 LLM 实现您正在测试的目标代码片段。指示您的 LLM 创建测试并运行它们也是一个很好的实践：它将能够将其发现的可能导致给定测试失败的错误添加到其上下文中，并据此行动，尝试使测试通过。

测试对于与 LLM 一起发展您的代码库至关重要，只有当所有当前测试都通过时才能继续前进。

基于属性的测试（TTD）在与 LLM 合作时非常有趣。测试整个值域/范围而不是仅仅是您指定特定值将有助于确保代理生成的代码即使在后续更改最终触及您未提前考虑到的边缘情况时仍然有效。每种语言都有很好的基于属性的测试库，例如 Python 的 hypothesis 或 JavaScript/TypeScript 的 fast-check。

始终检查 LLM 在尝试编写或修复测试时生成的代码也很重要：有时它们甚至会尝试生成一些硬编程输出以使测试通过 :-)

**如何确保安全？**

这里也适用非 AI 辅助编程的相同规则和最佳实践。研究更多关于它们并将其应用于您的代码。这里是一个初始的安全检查列表：

- **不要相信 AI 生成的代码。** 务必验证。请记住，您运行的代码的责任不在 AI，而在您自己！
- **不要将任何 API 密钥或其他秘密作为硬编程字符串存储，尤其是在前端代码中。** 将它们存储在后端作为受保护的环境变量（例如 Vercel 等平台提供此选项）。
- **查询 API 端点时，始终使用 HTTPS。**
- **创建 HTML 表单时，始终进行输入验证和清理。**
- **不要将敏感数据存储在 localStorage、sessionStorage 或 cookies 中。**
- **在您的包依赖项中运行验证器和安全漏洞扫描器。**

## All tools

| 编辑器（IDE）     | Cursor                  | Windsurf   |
| ----------------- | ----------------------- | ---------- |
|                   | Cline                   | OpenHands  |
|                   | VSCode + GitHub Copilot | Devin      |
|                   |                         |            |
| 命令行界面（CLI） | Claude Code             | Aider      |
|                   | OpenAI Codex CLI        | Roo Code   |
|                   | Gemini CLI              | Codebuff   |
|                   |                         |            |
| Web应用程序       | Bolt                    | v0         |
|                   | Replit                  | Lovable    |
|                   |                         |            |
| **后台/远程代理** | ZenCoder                | CodeRabbit |
|                   | Factory AI              |            |
|                   |                         |            |
| 有用的工具        | CodeGuide               | Specstory  |
|                   | Claude Taskmaster       | repomix    |
|                   | files-to-prompt         | repo2txt   |
